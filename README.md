## RAG WITH LLAMA

Retrieval Augmented Generation (RAG) is an architecture that augments the capabilities of a Large Language Model (LLM) like ChatGPT by adding an information retrieval system that provides grounding data. Adding an information retrieval system gives you control over grounding data used by an LLM when it formulates a response. For an enterprise solution, RAG architecture means that you can constrain generative AI to your enterprise content sourced from vectorized documents and images, and other data formats if you have embedding models for that content.

## Approaches for RAG 
![imagen](https://github.com/user-attachments/assets/a937d2b9-e38a-492e-9a7d-22671c726888)
## RAG with LangChain and LLAMA
![imagen](https://github.com/user-attachments/assets/497b1b30-4c8d-4f2b-bb98-efc8c74128f7)

## About the aplication

**Topic:** A POI(Point Of Interest) aplication for helping us to find the nearest restaurant to our current position, and also getting some information about food in american culture\
**Technologies:** Python, LangChain, AzureMaps, LLMs, IA, Generative models
